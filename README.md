![image](image.png)
>*A mathematically rigorous, physically grounded AI framework synthesizing theoretical physics, formal mathematics, and advanced machine learning.*


[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)


 # FishStick..üê†ü™æ

**Fishing that sticks!** üé£  

Na dat dere waa bwokee, its kay,i 
*Phhhisshtikk*

> - *Do Your Training Pipelines need Fixed?*
> - *Other Platforms Learning Curves to steep?*
> - *Tech/Dev, CLI Knowledge required for Advanced AI/Ml modeling?*
> - *Learning to Train got you or your business on hold?*
> - *Dont know how to fix it??*

***DONT WORRY or FRET***

`first just run`
'npm pip install 1000 deps'
`pipnpe i -curls! fish @goland`
 run dev init
 |‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢|

# ***IM ONLY KIDDING***


# FishStick.. üê†ü™æüöÄ
  "Is a Comprehensive and Robust
 AI/ML Training Ecosystem"

## Overview

**fishstick** implements 26 unified theoretical frameworks (A-Z) that combine:

- üéØ **Theoretical Physics**: Symmetry, renormalization, variational principles, thermodynamics
- üìê **Formal Mathematics**: Category theory, sheaf cohomology, differential geometry, type theory
- ü§ñ **Advanced ML**: Equivariant deep learning, neuro-symbolic integration, formal verification

### Core Philosophy

This framework treats AI not as empirical engineering but as a branch of mathematical physics, where:
- Neural architectures are **morphisms in dagger compact closed categories**
- Training dynamics are **gradient flows on statistical manifolds**
- Attention mechanisms respect **sheaf cohomology constraints**
- Models satisfy **thermodynamic bounds** on computation

## Installation

### Basic Installation

```bash
# Clone the repository
git clone https://github.com/NeuralBlitz/fishstick.git
cd fishstick

# Install core dependencies
pip install torch numpy scipy pyyaml

# Install package
pip install -e .
```

### Full Installation (with all features)

```bash
# Install all optional dependencies
pip install torchdiffeq torch-geometric

# Or install with extras
pip install -e ".[full]"
```

### Dependencies

**Core:**
- Python ‚â• 3.9
- PyTorch ‚â• 2.0
- NumPy ‚â• 1.21
- SciPy ‚â• 1.7

**Optional:**
- `torchdiffeq` - For Neural ODE solvers
- `torch-geometric` - For geometric graph neural networks

## Quick Start

### 1. Core Types and Manifolds

```python
import torch
from fishstick import (
    MetricTensor, SymplecticForm, PhaseSpaceState,
    StatisticalManifold, FisherInformationMetric
)

# Create statistical manifold
manifold = StatisticalManifold(dim=10)

# Fisher information metric
def log_prob(params):
    return (params**2).sum()

params = torch.randn(10, requires_grad=True)
metric = manifold.fisher_information(params, log_prob)

# Phase space for Hamiltonian dynamics
state = PhaseSpaceState(
    q=torch.randn(5),  # positions
    p=torch.randn(5)   # momenta
)
```

### 2. Categorical Structures

```python
from fishstick import (
    MonoidalCategory, Functor, NaturalTransformation,
    DaggerCategory, Lens
)

# Create monoidal category
cat = MonoidalCategory("NeuralCategory")

# Define objects and morphisms
from fishstick.categorical.category import Object

obj1 = Object(name="Input", shape=(784,))
obj2 = Object(name="Hidden", shape=(256,))

cat.add_object(obj1)
cat.add_object(obj2)

# Lens for bidirectional learning
lens = Lens(
    get=lambda x: x * 2,
    put=lambda s, a: s + a
)
```

### 3. Hamiltonian Neural Networks

```python
from fishstick import HamiltonianNeuralNetwork

# Energy-conserving neural network
hnn = HamiltonianNeuralNetwork(
    input_dim=10,
    hidden_dim=64,
    n_hidden=3
)

# Integrate dynamics
z0 = torch.randn(4, 20)  # batch of 4, phase space dim 20
trajectory = hnn.integrate(z0, n_steps=100, dt=0.01)

# trajectory shape: [101, 4, 20]
# Energy is conserved along trajectory
```

### 4. Sheaf-Optimized Attention

```python
from fishstick import SheafOptimizedAttention

# Attention with cohomological constraints
attn = SheafOptimizedAttention(
    embed_dim=256,
    num_heads=8,
    lambda_consistency=0.1
)

x = torch.randn(2, 100, 256)  # [batch, seq_len, embed_dim]

# Define open cover for local consistency
open_cover = [[0, 1, 2], [2, 3, 4], [4, 5, 6]]

output, weights = attn(x, open_cover=open_cover)
```

## The 6 Frameworks

### A. UniIntelli - Categorical‚ÄìGeometric‚ÄìThermodynamic Synthesis
```python
from fishstick.frameworks.uniintelli import create_uniintelli

model = create_uniintelli(
    input_dim=784,
    hidden_dim=256,
    output_dim=10
)
# 1.8M parameters
```

### B. HSCA - Holo-Symplectic Cognitive Architecture
```python
from fishstick.frameworks.hsca import create_hsca

model = create_hsca(input_dim=784, output_dim=10)
# 6.5M parameters - Energy-conserving Hamiltonian dynamics
```

### C. UIA - Unified Intelligence Architecture
```python
from fishstick.frameworks.uia import create_uia

model = create_uia(input_dim=784, output_dim=10)
# 1.7M parameters - CHNP + RG-AE + S-TF + DTL
```

### D. SCIF - Symplectic-Categorical Intelligence Framework
```python
from fishstick.frameworks.scif import create_scif

model = create_scif(input_dim=784, output_dim=10)
# 3.8M parameters - Fiber bundles + Hamiltonian dynamics
```

### E. UIF - Unified Intelligence Framework
```python
from fishstick.frameworks.uif import create_uif

model = create_uif(input_dim=784, output_dim=10)
# 367K parameters - 4-layer architecture
```

### F. UIS - Unified Intelligence Synthesis
```python
from fishstick.frameworks.uis import create_uis

model = create_uis(input_dim=784, output_dim=10)
# 861K parameters - Quantum-inspired + RG + Neuro-symbolic
```

### G. CRLS - Categorical Renormalization Learning Systems
```python
from fishstick.frameworks.crls import create_crls

model = create_crls(input_dim=784, output_dim=10)
# 958K parameters - Categorical RG flows + VAE
```

### H. ToposFormer - Topos-Theoretic Neural Networks
```python
from fishstick.frameworks.toposformer import create_toposformer

model = create_toposformer(input_dim=784, output_dim=10)
# 4.8M parameters - Sheaf integration + Hodge projection
```

### I. UIF-I - Renormalized Attention Module (RAM)
```python
from fishstick.frameworks.uif_i import create_uif_i

model = create_uif_i(input_dim=784, output_dim=10)
# 1.4M parameters - Scale-parameterized attention
```

### J. UIS-J - Node-at-Attention Mechanism
```python
from fishstick.frameworks.uis_j import create_uis_j

model = create_uis_j(input_dim=784, output_dim=10)
# 2.3M parameters - Cohomological attention + cross-synthesis
```

### K. UIA-K - Sheaf-LSTM with Fiber Bundle Attention
```python
from fishstick.frameworks.uia_k import create_uia_k

model = create_uia_k(input_dim=784, output_dim=10)
# 1.4M parameters - Fiber bundle attention + RG-MORL
```

### L. CRLS-L - Mathematical Intelligence Physics
```python
from fishstick.frameworks.crls_l import create_crls_l

model = create_crls_l(input_dim=784, output_dim=10)
# 375K parameters - Symplectic integrator + thermodynamic
```

### M. UIA-M - Renormalized Neural Flow
```python
from fishstick.frameworks.uia_m import create_uia_m

model = create_uia_m(input_dim=784, output_dim=10)
# 1.2M parameters - Symplectic dynamics + HBP
```

### N. UIS-N - Cross-Synthetic Node-at-Attention
```python
from fishstick.frameworks.uis_n import create_uis_n

model = create_uis_n(input_dim=784, output_dim=10)
# 4.1M parameters - Meta-rep signatures + lens optics
```

### O. UIA-O - Sheaf-Theoretic Neural Networks
```python
from fishstick.frameworks.uia_o import create_uia_o

model = create_uia_o(input_dim=784, output_dim=10)
# 822K parameters - Neural sheaf Laplacian + fiber bundles
```

### P. UIF-P - RG-Informed Hierarchical Networks
```python
from fishstick.frameworks.uif_p import create_uif_p

model = create_uif_p(input_dim=784, output_dim=10)
# 123K parameters - RG fixed points + symplectic SGD
```

### Q. UINet-Q - Categorical Quantum Neural Architecture
```python
from fishstick.frameworks.uinet_q import create_uinet_q

model = create_uinet_q(input_dim=784, output_dim=10)
# 2.0M parameters - ZX-calculus + categorical compilation
```

### R. UIF-R - Comprehensive Blueprint with Fisher Natural Gradient
```python
from fishstick.frameworks.uif_r import create_uif_r

model = create_uif_r(input_dim=784, output_dim=10)
# 291K parameters - Fisher information + monoidal composition
```

### S. USIF-S - Quantum Categorical Neural Networks (QCNN)
```python
from fishstick.frameworks.usif_s import create_usif_s

model = create_usif_s(input_dim=784, output_dim=10)
# 1.5M parameters - Quantum channels + topological features
```

### T. UIF-T - Hamiltonian-RG Flow Optimizer
```python
from fishstick.frameworks.uif_t import create_uif_t

model = create_uif_t(input_dim=784, output_dim=10)
# 330K parameters - Hamiltonian RG flow + auto-flow
```

### U. USIF-U - Thermodynamic Information Bounds
```python
from fishstick.frameworks.usif_u import create_usif_u

model = create_usif_u(input_dim=784, output_dim=10)
# 910K parameters - Hilbert space + quantum info bounds
```

### V. UIF-V - Information-Theoretic Dynamics
```python
from fishstick.frameworks.uif_v import create_uif_v

model = create_uif_v(input_dim=784, output_dim=10)
# 247K parameters - Stochastic action + type-theoretic verifier
```

### W. MCA-W - Meta-Cognitive Architecture
```python
from fishstick.frameworks.mca_w import create_mca_w

model = create_mca_w(input_dim=784, output_dim=10)
# 1.1M parameters - Meta-cognitive transformer + homotopy
```

### X. TTSIK-X - Topos-Theoretic Symplectic Intelligence Kernel
```python
from fishstick.frameworks.ttsik_x import create_ttsik_x

model = create_ttsik_x(input_dim=784, output_dim=10)
# 864K parameters - Symplectic sheaf + natural gradient HMC
```

### Y. CTNA-Y - Categorical-Thermodynamic Neural Architecture
```python
from fishstick.frameworks.ctna_y import create_ctna_y

model = create_ctna_y(input_dim=784, output_dim=10)
# 641K parameters - Traced monoidal + formal verification
```

### Z. SCIF-Z - Symplectic-Categorical Intelligence Framework
```python
from fishstick.frameworks.scif_z import create_scif_z

model = create_scif_z(input_dim=784, output_dim=10)
# 475K parameters - Causal intervention + topological analysis
```

## Advanced Features

### Neural ODEs

```python
from fishstick.neural_ode import NeuralODE, ODEFunction

# Define dynamics
odefunc = ODEFunction(dim=10, hidden_dim=64)

# Create Neural ODE with adaptive solver
node = NeuralODE(
    odefunc,
    t_span=(0.0, 1.0),
    method='dopri5',  # Dormand-Prince
    rtol=1e-5,
    atol=1e-6
)

z0 = torch.randn(4, 10)
z1 = node(z0)
```

### Geometric Graph Neural Networks

```python
from fishstick.graph import (
    EquivariantMessagePassing,
    GeometricGraphTransformer,
    MolecularGraphNetwork
)

# E(n)-equivariant message passing
layer = EquivariantMessagePassing(
    node_dim=64,
    edge_dim=0,
    hidden_dim=128
)

# Node features and 3D positions
x = torch.randn(100, 64)
pos = torch.randn(100, 3)
edge_index = torch.randint(0, 100, (2, 500))

x_out, pos_out = layer(x, pos, edge_index)
```

### Probabilistic / Bayesian Neural Networks

```python
from fishstick.probabilistic import (
    BayesianLinear,
    BayesianNeuralNetwork,
    MCDropout,
    DeepEnsemble
)

# Bayesian layer with variational inference
layer = BayesianLinear(784, 256, prior_sigma=1.0)
x = torch.randn(4, 784)
output = layer(x, sample=True)

# Full BNN
bnn = BayesianNeuralNetwork(
    input_dim=784,
    hidden_dims=[256, 128],
    output_dim=10
)

# Predict with uncertainty
mean, uncertainty = bnn.predict_with_uncertainty(x, n_samples=100)
```

### Normalizing Flows

```python
from fishstick.flows import RealNVP, Glow, MAF

# RealNVP coupling flows
flow = RealNVP(dim=8, n_coupling=8, hidden_dim=256)
x = torch.randn(100, 8)

# Density estimation
log_prob = flow.log_prob(x)

# Sampling
samples = flow.sample(1000)

# Glow with 1x1 convolutions
glow = Glow(dim=8, n_levels=3, n_steps_per_level=4)
```

### Equivariant Networks

```python
from fishstick.equivariant import (
    SE3EquivariantLayer,
    SE3Transformer,
    EquivariantMolecularEnergy
)

# SE(3)-equivariant layer
layer = SE3EquivariantLayer(
    in_features=32,
    out_features=32,
    hidden_dim=64
)

features = torch.randn(10, 32)
coords = torch.randn(10, 3)  # 3D positions
edge_index = torch.randint(0, 10, (2, 30))

f_out, c_out = layer(features, coords, edge_index)
# c_out is equivariant to rotations/reflections
```

### Causal Inference

```python
from fishstick.causal import (
    CausalGraph,
    StructuralCausalModel,
    CausalDiscovery
)

# Define causal DAG
import numpy as np
adjacency = np.array([
    [0, 1, 0],
    [0, 0, 1],
    [0, 0, 0]
])
graph = CausalGraph(n_nodes=3, adjacency=adjacency)

# Structural Causal Model
scm = StructuralCausalModel(graph, hidden_dim=64)

# Observational sampling
sample = scm.forward()

# Interventional: do(X=2.0)
intervention = {0: torch.tensor([[2.0]])}
sample_do = scm.do_calculus(intervention_node=0, 
                           value=torch.tensor([[2.0]]))

# Causal discovery from data
data = np.random.randn(1000, 3)
learned_graph = CausalDiscovery.pc_algorithm(data)
```

## Architecture

```
fishstick/
‚îú‚îÄ‚îÄ core/               # Fundamental types and manifolds
‚îú‚îÄ‚îÄ categorical/        # Category theory structures
‚îú‚îÄ‚îÄ geometric/          # Differential geometry
‚îú‚îÄ‚îÄ dynamics/           # Hamiltonian & thermodynamic
‚îú‚îÄ‚îÄ sheaf/             # Sheaf theory
‚îú‚îÄ‚îÄ rg/                # Renormalization group
‚îú‚îÄ‚îÄ verification/      # Formal verification
‚îú‚îÄ‚îÄ frameworks/        # 26 unified frameworks (A-Z)
‚îú‚îÄ‚îÄ neural_ode/        # Neural ODEs
‚îú‚îÄ‚îÄ graph/             # Geometric GNNs
‚îú‚îÄ‚îÄ probabilistic/     # Bayesian methods
‚îú‚îÄ‚îÄ flows/             # Normalizing flows
‚îú‚îÄ‚îÄ equivariant/       # Equivariant networks
‚îî‚îÄ‚îÄ causal/            # Causal inference
```

## Testing

Run the test suite:

```bash
# Core framework tests
python test_all.py

# Advanced features tests
python test_advanced.py

# Run all tests
python -m pytest test_all.py test_advanced.py -v
```

### Test Coverage

- **Core Framework**: 13/13 tests passed
- **Advanced Features**: 6/6 tests passed
- **Total**: 19/19 tests passed ‚úÖ

## Performance

All frameworks tested on synthetic data:

| Framework | Parameters | Forward Pass | Framework | Parameters | Forward Pass |
|-----------|------------|--------------|-----------|------------|--------------|
| UniIntelli | 1.8M | ‚úì | UIF-I | 1.4M | ‚úì |
| HSCA | 6.5M | ‚úì | UIS-J | 2.3M | ‚úì |
| UIA | 1.7M | ‚úì | UIA-K | 1.4M | ‚úì |
| SCIF | 3.8M | ‚úì | CRLS-L | 375K | ‚úì |
| UIF | 367K | ‚úì | UIA-M | 1.2M | ‚úì |
| UIS | 861K | ‚úì | UIS-N | 4.1M | ‚úì |
| CRLS | 958K | ‚úì | UIA-O | 822K | ‚úì |
| ToposFormer | 4.8M | ‚úì | UIF-P | 123K | ‚úì |
| UINet-Q | 2.0M | ‚úì | USIF-S | 1.5M | ‚úì |
| UIF-R | 291K | ‚úì | UIF-T | 330K | ‚úì |
| USIF-U | 910K | ‚úì | UIF-V | 247K | ‚úì |
| MCA-W | 1.1M | ‚úì | TTSIK-X | 864K | ‚úì |
| CTNA-Y | 641K | ‚úì | SCIF-Z | 475K | ‚úì |

**Total: 26 frameworks, ~27M parameters across all base configurations**

## Documentation

For detailed mathematical documentation, see:

- `A.md` - UniIntelli: Categorical‚ÄìGeometric‚ÄìThermodynamic Synthesis
- `B.md` - HSCA: Holo-Symplectic Cognitive Architecture  
- `C.md` - UIA: Unified Intelligence Architecture
- `D.md` - SCIF: Symplectic-Categorical Intelligence Framework
- `E.md` - UIF: Unified Intelligence Framework
- `F.md` - UIS: Unified Intelligence Synthesis
- `G.md` - CRLS: Categorical Renormalization Learning Systems
- `H.md` - ToposFormer: Topos-Theoretic Neural Networks
- `I.md` - UIF-I: Renormalized Attention Module
- `J.md` - UIS-J: Node-at-Attention Mechanism
- `K.md` - UIA-K: Sheaf-LSTM with Fiber Bundle Attention
- `L.md` - CRLS-L: Mathematical Intelligence Physics
- `M.md` - UIA-M: Renormalized Neural Flow
- `N.md` - UIS-N: Cross-Synthetic Node-at-Attention
- `O.md` - UIA-O: Sheaf-Theoretic Neural Networks
- `P.md` - UIF-P: RG-Informed Hierarchical Networks
- `Q.md` - UINet-Q: Categorical Quantum Neural Architecture
- `R.md` - UIF-R: Comprehensive Blueprint with Fisher Natural Gradient
- `S.md` - USIF-S: Quantum Categorical Neural Networks
- `T.md` - UIF-T: Hamiltonian-RG Flow Optimizer
- `U.md` - USIF-U: Thermodynamic Information Bounds
- `V.md` - UIF-V: Information-Theoretic Dynamics
- `W.md` - MCA-W: Meta-Cognitive Architecture
- `X.md` - TTSIK-X: Topos-Theoretic Symplectic Intelligence Kernel
- `Y.md` - CTNA-Y: Categorical-Thermodynamic Neural Architecture
- `Z.md` - SCIF-Z: Symplectic-Categorical Intelligence Framework

## Mathematical Foundations

### Key Theorems Implemented

1. **Natural Gradient = Geodesic Flow**: Theorem 2.1 - Natural gradient descent is the time-Œ∑ flow of the gradient vector field w.r.t. Levi-Civita connection

2. **SOA Conserves Sheaf Cohomology**: Theorem 4.1 - Sheaf-Optimized Attention preserves Œ¥¬π(s) = 0 up to O(Œ∑¬≤)

3. **TGF Convergence**: Theorem 5.1 - Thermodynamic Gradient Flow converges under non-equilibrium fluctuations

4. **No-Cloning in Learn**: Lemma 2.1 - No morphism Œî: A ‚Üí A ‚äó A exists in the category of learning processes

## Contributing

We welcome contributions! Areas of interest:

- Implementing higher sheaf cohomology (H¬≤) for mode connectivity
- Quantum-categorical neural networks
- Real-time formal verification with neural theorem proving
- Unified scaling laws from RG fixed points

Please read [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## Citation

If you use this framework in your research, please cite:

```bibtex
@software{fishstick_2026,
  title={fishstick: A Mathematically Rigorous AI Framework},
  author={[Your Name]},
  url={https://github.com/NeuralBlitz/fishstick},
  year={2026}
}
```

## License

This project is licensed under the MIT License - see [LICENSE](LICENSE) file.

## Acknowledgments

This framework synthesizes insights from:
- Statistical mechanics and thermodynamics
- Differential geometry and information geometry
- Category theory and type theory
- Symplectic geometry and Hamiltonian mechanics
- Sheaf theory and algebraic topology

The era of black-box AI is ending. The era of **principled intelligence** begins now.
